{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TVM-Ellipses-LoDoPab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uco9yMnAmbIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b83b43-bdf7-43aa-90d4-b207d4f4981d"
      },
      "source": [
        "import pickle\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# update path to import from Drive\n",
        "import sys\n",
        "sys.path.append('content/drive/MyDrive')\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = 'cuda:0' # \"cpu\" \n",
        "\n",
        "use_ellipses = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUdNaX-9LRQq",
        "outputId": "dd03dc65-8d92-4778-ecaf-7452d5d9cf69"
      },
      "source": [
        "folder_path = './'\n",
        "if use_ellipses:\n",
        "    data_path = folder_path + 'FFPN-Ellipse-TrainingData-0.015IndividualNoise.pkl'\n",
        "else:\n",
        "    data_path = folder_path + 'FFPN-Lodopab-TrainingData-0.015IndividualNoise.pkl'\n",
        "\n",
        "if os.path.isfile(data_path):\n",
        "    print(\"FFPN data .pkl file already exists.\")\n",
        "else:\n",
        "    print(\"Extracting data from .pkl file.\")\n",
        "    if use_ellipses:\n",
        "        with zipfile.ZipFile('/content/drive/MyDrive/FixedPointNetworks/FFPN-Ellipse-TrainingData-IndividualNoise.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall('./')\n",
        "    else:\n",
        "        with zipfile.ZipFile('/content/drive/MyDrive/FixedPointNetworks/FFPN-Lodopab-TrainingData-IndividualNoise.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall('./')        \n",
        "    print(\"Extraction complete.\")\n",
        "\n",
        "    sys.path.append('content/drive/MyDrive/FixedPointNetworks')\n",
        "    sys.path.insert(0,'/content/drive/MyDrive/FixedPointNetworks')  \n",
        "\n",
        "state = torch.load(data_path)\n",
        "A = state['A'].to(device)\n",
        "u_train = state['u_true_train']\n",
        "u_test = state['u_true_test']\n",
        "data_obs_train = state['data_obs_train']\n",
        "data_obs_test = state['data_obs_test']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FFPN data .pkl file already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KSnNLuuUyNk"
      },
      "source": [
        "plt.figure()\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(u_train[0,0,:,:])\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(data_obs_train[0,0,:,:])\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzUyStSFmu0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91904f0d-226a-4a51-91a8-4969992923a2"
      },
      "source": [
        "# Create training datasets\n",
        "batch_size  = 15\n",
        "data_train  = TensorDataset(u_train, data_obs_train)\n",
        "data_loader = DataLoader(dataset=data_train, batch_size=batch_size, shuffle=True)\n",
        "n_batches   = int(len(data_loader.dataset)/batch_size)\n",
        "# Info about the dataset\n",
        "print()\n",
        "print(f'u_train.min(): {u_train.min()}')\n",
        "print(f'u_train.max(): {u_train.max()}')\n",
        "print(\"data_obs_train.shape = \", data_obs_train.shape)\n",
        "print('n_batches = ', n_batches)\n",
        "#print()*7410"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "u_train.min(): 0.0\n",
            "u_train.max(): 1.0\n",
            "data_obs_train.shape =  torch.Size([20000, 1, 30, 183])\n",
            "n_batches =  1333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMpjvT8vbI5K"
      },
      "source": [
        "class TVM_Net(nn.Module):\n",
        "    def __init__(self, A, lambd=0.1, alpha=0.1, beta=0.1, eps=1.0):\n",
        "        super().__init__()\n",
        "        self.A = A\n",
        "        self.At = A.t() \n",
        "        self.lambd = lambd\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.shrink = torch.nn.Softshrink(lambd=lambd)\n",
        "        self.eps = eps\n",
        "\n",
        "    def name(self) -> str:\n",
        "        return \"TVM_Net\"\n",
        "\n",
        "    def device(self):\n",
        "        return \"cuda:0\" #next(self.parameters()).data.device\n",
        "\n",
        "    def box_proj(self, u):\n",
        "        return torch.clamp(u, min=0.0, max=1.0)\n",
        "    \n",
        "    def D(self, u):  \n",
        "        u = u.view(128, 128, u.shape[-1])\n",
        "        Dux = torch.roll(u, 1, 0) - u\n",
        "        Dux = Dux.view(128 ** 2, u.shape[-1])\n",
        "        Duy = torch.roll(u, 1, 1) - u\n",
        "        Duy = Duy.view(128 ** 2, u.shape[-1])\n",
        "        Du  = torch.cat((Dux, Duy), 0)\n",
        "        return Du\n",
        "\n",
        "    def Dt(self, p): \n",
        "        p    = p.view(256, 128, p.shape[1])\n",
        "        px   = p[0:128, :, :]\n",
        "        Dtpx = torch.roll(px, -1, 0) - px\n",
        "        Dtpx = Dtpx.view(128 ** 2, p.shape[2])\n",
        "\n",
        "        py   = p[128:256, :, :]\n",
        "        Dtpy = torch.roll(py, -1, 1) - py\n",
        "        Dtpy = Dtpy.view(128 ** 2, p.shape[2])\n",
        "        Dtp  = Dtpx + Dtpy\n",
        "        return Dtp        \n",
        "\n",
        "    def ball_proj(self, w, d, eps):\n",
        "        ''' Project w onto the ball B(d, eps)\n",
        "        ''' \n",
        "        dist = torch.norm(w - d, dim=0) \n",
        "        out_ball = dist > eps  \n",
        "        proj = w.clone() \n",
        "        proj[:, out_ball] = d[:, out_ball] + (w[:, out_ball] - d[:, out_ball]) / dist[out_ball]\n",
        "        return proj\n",
        "\n",
        "    def forward(self, d, tol=1.0e-3, max_depth=12, \n",
        "                depth_warning=False):\n",
        "      \n",
        "        self.depth = 0.0\n",
        "\n",
        "        # Initialize sequences \n",
        "        d    = d.view(d.size()[0],-1).to(self.device()) \n",
        "        d    = d.permute(1,0)         \n",
        "        uk   = torch.zeros((128 ** 2, d.size()[1]), device=self.device())\n",
        "        pk   = self.D(uk) \n",
        "        wk   = torch.matmul(self.A, uk)  \n",
        "        nuk1 = torch.zeros(pk.size(), device=self.device())\n",
        "        nuk2 = torch.zeros(d.size(), device=self.device())   \n",
        "\n",
        "        for _ in range(max_depth):\n",
        "\n",
        "            # TVM updates\n",
        "            res1 = self.Dt(nuk1 + self.alpha * (self.D(uk) - pk))\n",
        "            Auk  = torch.matmul(self.A, uk)\n",
        "            res2 = torch.matmul(self.At, nuk2 + self.alpha * (Auk - wk))\n",
        "            rk   = self.beta * (res1 + res2)\n",
        "            uk   = self.box_proj(uk - rk)\n",
        "            \n",
        "            res  = self.lambd * (nuk1 + self.alpha * (self.D(uk)-pk))\n",
        "            pk   = self.shrink(pk + res)\n",
        "\n",
        "            Auk  = torch.matmul(self.A, uk)\n",
        "            res  = self.lambd * (nuk2 + self.alpha * (Auk - wk))\n",
        "            wk   = self.ball_proj(wk + res, d, self.eps)\n",
        " \n",
        "            nuk1 = nuk1 + self.alpha * (self.D(uk) - pk)\n",
        "            nuk2 = nuk2 + self.alpha * (torch.matmul(self.A, uk) - wk)\n",
        "\n",
        "        self.depth = max_depth\n",
        "        if self.depth >= max_depth and depth_warning:\n",
        "            print(\"\\nWarning: Max Depth Reached - Break Forward Loop\\n\")\n",
        "        \n",
        "        #print(\"final = uk size = \", uk.size())\n",
        "        uk = uk.permute(1,0)        \n",
        "        return uk.view(uk.shape[0], 1, 128, 128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMcRhjnqm-Uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d7e5d5-d8ac-4a41-8e79-7cf3ddad0067"
      },
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# Set up training parameters\n",
        "#-------------------------------------------------------------------------------\n",
        "Phi = TVM_Net(A.to(device))\n",
        "Phi = Phi.to(device)\n",
        "print(Phi)\n",
        "pytorch_total_params = sum(p.numel() for p in Phi.parameters() if p.requires_grad)\n",
        "print(f'Number of trainable parameters: {pytorch_total_params}')\n",
        "\n",
        "max_epochs = 2000 \n",
        "max_depth  = 250 \n",
        "criterion  = torch.nn.MSELoss()  \n",
        "fmt        = '[{:2d}/{:2d}]: train_loss = {:7.3e} | ' \n",
        "fmt       += 'depth = {:5.1f} | lr = {:5.1e} | time = {:4.1f} sec'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 0\n",
            "TVM_Net(\n",
            "  (shrink): Softshrink(0.1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEr2wb91nCoa"
      },
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# Execute Training\n",
        "#-------------------------------------------------------------------------------\n",
        "best_loss = 1.0e10 \n",
        "\n",
        "for epoch in range(max_epochs): \n",
        "  sleep(0.5)  # slows progress bar so it won't print on multiple lines\n",
        "  tot = len(data_loader)\n",
        "  loss_ave = 0.0\n",
        "  start_time_epoch = time.time() \n",
        "  with tqdm(total=tot, unit=\" batch\", leave=False, ascii=True) as tepoch:      \n",
        "    for idx, (u_batch, d) in enumerate(data_loader): \n",
        "        u_batch    = u_batch.to(device) \n",
        "        batch_size = u_batch.shape[0]\n",
        "        train_batch_size = d.shape[0] # re-define if batch size changes\n",
        "        u = Phi(d.to(device), max_depth=max_depth) # add snippet for hiding\n",
        "        output = criterion(u, u_batch)\n",
        "        train_loss = output.detach().cpu().numpy()\n",
        "        loss_ave += train_loss * train_batch_size\n",
        " \n",
        "        if idx%2 == 0:\n",
        "            # compute test image \n",
        "            Phi.eval()\n",
        "            u_test_approx = Phi(data_obs_test[0:1,:,:,:], max_depth=max_depth)\n",
        "\n",
        "            plt.figure()\n",
        "            plt.subplot(2,2,1)\n",
        "            plt.imshow(u_batch[0,0,:,:].cpu(), vmin=0, vmax=1)\n",
        "            plt.title('u true train')\n",
        "            plt.subplot(2,2,2)\n",
        "            plt.imshow(u[0,0,:,:].detach().cpu(), vmin=0, vmax=1)\n",
        "            plt.title('u approx train')\n",
        "            plt.subplot(2,2,3)\n",
        "            plt.imshow(u_test[0,0,:,:].cpu(), vmin=0, vmax=1)\n",
        "            plt.title('u true test')\n",
        "            plt.subplot(2,2,4)\n",
        "            plt.imshow(u_test_approx[0,0,:,:].detach().cpu(), vmin=0, vmax=1)\n",
        "            plt.title('u approx test')\n",
        "            plt.show() \n",
        "            Phi.train() \n",
        "\n",
        "        tepoch.update(1)\n",
        "        tepoch.set_postfix(train_loss=\"{:5.2e}\".format(train_loss),\n",
        "                            depth=\"{:5.1f}\".format(Phi.depth))\n",
        "    \n",
        "\n",
        "  loss_ave = loss_ave/len(data_loader.dataset)\n",
        "  end_time_epoch = time.time()\n",
        "  time_epoch = end_time_epoch - start_time_epoch\n",
        "  #lr_scheduler.step()\n",
        "  print(fmt.format(epoch+1, max_epochs, loss_ave, Phi.depth, \n",
        "                   0.0,\n",
        "                   time_epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyxCl1Id_Fwb"
      },
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "n_samples = u_test.shape[0]\n",
        "\n",
        "data_test     = TensorDataset(u_test, data_obs_test)\n",
        "test_data_loader     = DataLoader(dataset=data_test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "def compute_avg_SSIM_PSNR(u_true, u_gen, n_mesh, data_range):\n",
        "    # assumes images are size n_samples x n_features**2 and are detached\n",
        "    n_samples = u_true.shape[0]\n",
        "    u_true = u_true.reshape(n_samples, n_mesh, n_mesh).cpu().numpy()\n",
        "    u_gen  = u_gen.reshape(n_samples, n_mesh, n_mesh).cpu().numpy()\n",
        "    ssim_val = 0\n",
        "    psnr_val = 0\n",
        "    for j in range(n_samples):\n",
        "        ssim_val = ssim_val + ssim(u_true[j,:,:], u_gen[j,:,:], data_range=data_range)\n",
        "        psnr_val = psnr_val + psnr(u_true[j,:,:], u_gen[j,:,:], data_range=data_range)\n",
        "    return ssim_val/n_samples, psnr_val/n_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrt0leh7qg59"
      },
      "source": [
        "\n",
        "test_loss_ave = 0\n",
        "test_PSNR_ave = 0\n",
        "test_SSIM_ave = 0\n",
        "with torch.no_grad():\n",
        "    for idx, (u_batch, d) in enumerate(test_data_loader): \n",
        "\n",
        "        u_batch    = u_batch.to(device) \n",
        "        batch_size = u_batch.shape[0]\n",
        "        temp       = u_batch.view(batch_size, -1)\n",
        "        temp       = temp.permute(1,0)        \n",
        "        test_batch_size = d.shape[0] # re-define if batch size changes\n",
        "        Phi.eval()\n",
        "        u = Phi(d, max_depth=max_depth) # add snippet for hiding\n",
        "        output = criterion(u, u_batch)\n",
        "        test_loss = output.detach().cpu().numpy()\n",
        "        test_SSIM, test_PSNR = compute_avg_SSIM_PSNR(u_batch, u, 128, 1)\n",
        "        test_PSNR_ave += test_PSNR * test_batch_size\n",
        "        test_loss_ave += test_loss * test_batch_size\n",
        "        test_SSIM_ave += test_SSIM * test_batch_size\n",
        "\n",
        "        print('test_PSNR = {:7.3e}'.format(test_PSNR))\n",
        "        print('test_SSIM = {:7.3e}'.format(test_SSIM))\n",
        "        print('test_loss = {:7.3e}'.format(test_loss))\n",
        "        if idx%1 == 0:\n",
        "            # compute test image \n",
        "            plt.figure()\n",
        "            plt.subplot(1,2,1)\n",
        "            plt.imshow(u_batch[0,0,:,:].cpu(), vmin=0, vmax=1)\n",
        "            plt.title('u true')\n",
        "            plt.subplot(1,2,2)\n",
        "            plt.imshow(u[0,0,:,:].detach().cpu(), vmin=0, vmax=1)\n",
        "            plt.title('u approx')\n",
        "            plt.show()  \n",
        "\n",
        "print('\\n\\nSUMMARY')\n",
        "print('test_loss_ave =  {:7.3e}'.format(test_loss_ave / len(data_loader.dataset)))\n",
        "print('test_PSNR_ave =  {:7.3e}'.format(test_PSNR_ave / len(data_loader.dataset)))\n",
        "print('test_SSIM_ave =  {:7.3e}'.format(test_SSIM_ave / len(data_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDWZLuTs_Dpl"
      },
      "source": [
        "if use_ellipses:\n",
        "    ind_val = 0\n",
        "else:\n",
        "    ind_val = 1000\n",
        "\n",
        "u = Phi(data_obs_test[ind_val,:,:,:], max_depth=max_depth).view(128,128)\n",
        "u_true = u_test[ind_val,0,:,:]\n",
        "def string_ind(index):\n",
        "    if index < 10:\n",
        "        return '000' + str(index)\n",
        "    elif index < 100:\n",
        "        return '00' + str(index)\n",
        "    elif index < 1000:\n",
        "        return '0' + str(index)\n",
        "    else:\n",
        "        return str(index)\n",
        "\n",
        "cmap = 'gray'\n",
        "fig = plt.figure()\n",
        "plt.imshow(np.rot90(u.detach().cpu().numpy()),cmap=cmap, vmin=0, vmax=1)\n",
        "plt.axis('off')\n",
        "\n",
        "data_type = 'Ellipse' if use_ellipses else 'Lodopab'\n",
        "\n",
        "save_loc = './drive/MyDrive/FixedPointNetworks/Learned_Feasibility_' + data_type + '_TVM_ind_' + string_ind(ind_val) + '.pdf'\n",
        "plt.savefig(save_loc,bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"SSIM: \", compute_avg_SSIM_PSNR(u_true.view(1,128,128), u.view(1,128,128).detach(), 128, 1))\n",
        "\n",
        "############\n",
        "# TRUE\n",
        "###########\n",
        "\n",
        "cmap = 'gray'\n",
        "fig = plt.figure()\n",
        "plt.imshow(np.rot90(u_true.detach().cpu().numpy()),cmap=cmap, vmin=0, vmax=1)\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "save_loc = './drive/MyDrive/FixedPointNetworks/Learned_Feasibility_' + data_type + '_GT_ind_' + string_ind(ind_val) + '.pdf'\n",
        "plt.savefig(save_loc,bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}