{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "F-FPN-Ellipses.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uco9yMnAmbIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0739b7-ce60-4f9a-debe-681f75df2470"
      },
      "source": [
        "import pickle\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# update path to import from Drive\n",
        "import sys\n",
        "sys.path.append('content/drive/MyDrive')\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = 'cuda:0' # \"cpu\" "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUdNaX-9LRQq",
        "outputId": "b9430bf6-d139-47fa-9052-3a856a74e3f2"
      },
      "source": [
        "folder_path = './'\n",
        "data_path = folder_path + 'FFPN-Ellipse-TrainingData-0.015IndividualNoise.pkl'\n",
        "\n",
        "if os.path.isfile(data_path):\n",
        "    print(\"FFPN data .pkl file already exists.\")\n",
        "else:\n",
        "    print(\"Extracting data from .pkl file.\")\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/FixedPointNetworks/FFPN-Ellipse-TrainingData-IndividualNoise.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('./')\n",
        "    print(\"Extraction complete.\")\n",
        "\n",
        "    sys.path.append('content/drive/MyDrive/FixedPointNetworks')\n",
        "    sys.path.insert(0,'/content/drive/My Drive/FixedPointNetworks')  \n",
        "\n",
        "state = torch.load(data_path)\n",
        "A = state['A'].to(device)\n",
        "u_train = state['u_true_train']\n",
        "u_test = state['u_true_test']\n",
        "data_obs_train = state['data_obs_train']\n",
        "data_obs_test = state['data_obs_test']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting data from .pkl file.\n",
            "Extraction complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KSnNLuuUyNk"
      },
      "source": [
        "plt.figure()\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(u_train[0,0,:,:])\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(data_obs_train[0,0,:,:])\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa00-1hAKi_7"
      },
      "source": [
        "print(\"A size = \", A.size())\n",
        "S = torch.diag(torch.count_nonzero(A, dim=0) ** -1.0).float()\n",
        "S = S.to(device)\n",
        "print(S)\n",
        "print('S size = ', S.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lp8aVZbd7oO"
      },
      "source": [
        "Create training datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzUyStSFmu0p"
      },
      "source": [
        "batch_size  = 15\n",
        "data_train  = TensorDataset(u_train[0:10000,:,:,:], data_obs_train[0:10000,:,:,:])\n",
        "data_loader = DataLoader(dataset=data_train, batch_size=batch_size, shuffle=True)\n",
        "n_batches   = int(len(data_loader.dataset)/batch_size)\n",
        "\n",
        "print()\n",
        "print(f'u_train.min(): {u_train.min()}')\n",
        "print(f'u_train.max(): {u_train.max()}')\n",
        "print(\"data_obs_train.shape = \", data_obs_train.shape)\n",
        "print('n_batches = ', n_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL4cX5Dedz9k"
      },
      "source": [
        "Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMpjvT8vbI5K"
      },
      "source": [
        "class Regularizer_Net(nn.Module):\n",
        "    def __init__(self, D, M, res_net_contraction=0.99, res_layers=4,\n",
        "                 num_channels = 42):\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.leaky_relu = nn.LeakyReLU(0.05)\n",
        "        self.gamma = res_net_contraction  \n",
        "        self.D = D \n",
        "        self.M = M\n",
        "        self.Mt = M.t()        \n",
        "        in_channels = lambda i: 1 if i == 0 else num_channels\n",
        "        out_channels = lambda i: 1 if i == res_layers-1 else num_channels\n",
        "        self.convs = nn.ModuleList([nn.Sequential(nn.Conv2d(\n",
        "                                            in_channels=in_channels(i), \n",
        "                                            out_channels=num_channels, \n",
        "                                            kernel_size=3, stride=1, \n",
        "                                            padding=(1,1)),\n",
        "                                            self.leaky_relu,\n",
        "                                            nn.Conv2d(in_channels=num_channels, \n",
        "                                            out_channels=out_channels(i), \n",
        "                                            kernel_size=3, stride=1, \n",
        "                                            padding=(1,1)),\n",
        "                                            self.leaky_relu)\n",
        "                                    for i in range(res_layers)]) \n",
        "\n",
        "    def name(self) -> str:\n",
        "        return \"Regularizer_Net\"\n",
        "\n",
        "    def device(self):\n",
        "        return next(self.parameters()).data.device\n",
        "\n",
        "    def _T(self, u, d):\n",
        "        batch_size = u.shape[0]\n",
        "\n",
        "        # Learned Regularization Operator\n",
        "        for idx, conv in enumerate(self.convs):\n",
        "            u_ref = u if idx + 1 < len(self.convs) \\\n",
        "                    else u[:,0,:,:].view(batch_size,1,128,128)\n",
        "            Du = torch.roll(u, 1, dims=-1) - u if idx%2 == 0 \\\n",
        "                 else torch.roll(u, 1, dims=-2) - u\n",
        "            u = u_ref + conv(Du)\n",
        "        u = torch.clamp(u, min=-1.0e1, max=1.0e1)\n",
        "\n",
        "        # Constraints Projection\n",
        "        u_vec = u.view(batch_size, -1).to(self.device())\n",
        "        u_vec = u_vec.permute(1,0).to(self.device())   \n",
        "        d = d.view(batch_size,-1).to(self.device())\n",
        "        d = d.permute(1,0)\n",
        "        res = torch.matmul(self.Mt, self.M.matmul(u_vec) - d)\n",
        "        res = 1.99 * torch.matmul(self.D.to(self.device()), res)\n",
        "        res = res.permute(1,0)\n",
        "        res = res.view(batch_size, 1, 128, 128).to(self.device())\n",
        "        return u - res\n",
        "\n",
        "    def normalize_lip_const(self, u, d):\n",
        "        ''' Scale convolutions in R to make it gamma Lipschitz\n",
        "\n",
        "            It should hold that |R(u,v) - R(w,v)| <= gamma * |u-w| for all u\n",
        "            and w. If this doesn't hold, then we must rescale the convolution.\n",
        "            Consider R = I + Conv. To rescale, ideally we multiply R by\n",
        "\n",
        "                norm_fact = gamma * |u-w| / |R(u,v) - R(w,v)|,\n",
        "            \n",
        "            averaged over a batch of samples, i.e. R <-- norm_fact * R. The \n",
        "            issue is that ResNets include an identity operation, which we don't \n",
        "            wish to rescale. So, instead we use\n",
        "                \n",
        "                R <-- I + norm_fact * Conv,\n",
        "            \n",
        "            which is accurate up to an identity term scaled by (norm_fact - 1).\n",
        "            If we do this often enough, then norm_fact ~ 1.0 and the identity \n",
        "            term is negligible.\n",
        "\n",
        "            Note: BatchNorm and ReLUs are nonexpansive when...???\n",
        "        '''\n",
        "        noise_u = 0.05 * torch.randn(u.size(), device=self.device()) \n",
        "        w = u.clone() + noise_u\n",
        "        w = w.to(self.device())\n",
        "        Twd = self._T(w, d)\n",
        "        Tud = self._T(u, d)\n",
        "        T_diff_norm = torch.mean(torch.norm(Twd - Tud, dim=1))\n",
        "        u_diff_norm = torch.mean(torch.norm(w - u, dim=1))\n",
        "        R_is_gamma_lip = T_diff_norm <= self.gamma * u_diff_norm\n",
        "        if not R_is_gamma_lip:\n",
        "            normalize_factor = (self.gamma * u_diff_norm / T_diff_norm) ** (1.0 / len(self.convs))\n",
        "            print(\"normalizing!\")\n",
        "            for i in range(len(self.convs)):\n",
        "                self.convs[i][0].weight.data *= normalize_factor\n",
        "                self.convs[i][0].bias.data *= normalize_factor\n",
        "                self.convs[i][2].weight.data *= normalize_factor\n",
        "                self.convs[i][2].bias.data *= normalize_factor                \n",
        "\n",
        "    def forward(self, d, eps=1.0e-3, max_depth=100, \n",
        "                depth_warning=False):\n",
        "        ''' FPN forward prop\n",
        "\n",
        "            With gradients detached, find fixed point. During forward iteration,\n",
        "            u is updated via R(u,Q(d)) and Lipschitz constant estimates are\n",
        "            refined. Gradient are attached performing one final step.\n",
        "        '''         \n",
        "        with torch.no_grad():\n",
        "            self.depth = 0.0\n",
        "            u = torch.zeros((d.size()[0], 1, 128, 128), \n",
        "                            device=self.device())\n",
        "            u_prev = np.Inf*torch.ones(u.shape, device=self.device())            \n",
        "            all_samp_conv = False\n",
        "            while not all_samp_conv and self.depth < max_depth:\n",
        "                u_prev = u.clone()   \n",
        "                u = self._T(u, d)\n",
        "                res_norm = torch.max(torch.norm(u - u_prev, dim=1)) \n",
        "                self.depth += 1.0\n",
        "                all_samp_conv = res_norm <= eps\n",
        "            \n",
        "            if self.training:\n",
        "                self.normalize_lip_const(u, d)\n",
        "\n",
        "        if self.depth >= max_depth and depth_warning:\n",
        "            print(\"\\nWarning: Max Depth Reached - Break Forward Loop\\n\")\n",
        "\n",
        "        return self._T(u, d)                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oGQCMmFeBR0"
      },
      "source": [
        "Set up training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMcRhjnqm-Uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43769bef-46f8-433e-ab3f-786b14e92d62"
      },
      "source": [
        "Phi = Regularizer_Net(S.to(device), A.to(device))\n",
        "Phi = Phi.to(device)\n",
        "\n",
        "pytorch_total_params = sum(p.numel() for p in Phi.parameters() if p.requires_grad)\n",
        "print(f'Number of trainable parameters: {pytorch_total_params}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 96307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDoVIWSQ3uR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0b2575-e058-4db6-8614-a3dc565599f2"
      },
      "source": [
        "max_epochs    = 25 \n",
        "max_depth     = 100\n",
        "eps           = 5.0e-3\n",
        "\n",
        "criterion = torch.nn.MSELoss()  \n",
        "learning_rate = 2.5e-5\n",
        "optimizer = optim.Adam(Phi.parameters(), lr=learning_rate)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "fmt        = '[{:2d}/{:2d}]: train_loss = {:7.3e} | ' \n",
        "fmt       += 'depth = {:5.1f} | lr = {:5.1e} | time = {:4.1f} sec'\n",
        "\n",
        "load_weights = True\n",
        "if load_weights:\n",
        "    # FOR RELOADING\n",
        "    state = torch.load('./drive/MyDrive/FixedPointNetworks/Feasible_FPN_Ellipses_weights.pth', map_location=torch.device(device)) \n",
        "    Phi.load_state_dict(state['Phi_state_dict'])\n",
        "    print('Loaded Phi from file.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Phi from file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW3jgaTCecRc"
      },
      "source": [
        "Execute Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEr2wb91nCoa"
      },
      "source": [
        "best_loss = 1.0e10 \n",
        "\n",
        "for epoch in range(max_epochs): \n",
        "  sleep(0.5)  # slows progress bar so it won't print on multiple lines\n",
        "  tot = len(data_loader)\n",
        "  loss_ave = 0.0\n",
        "  start_time_epoch = time.time() \n",
        "  with tqdm(total=tot, unit=\" batch\", leave=False, ascii=True) as tepoch:\n",
        "      \n",
        "    for idx, (u_batch, d) in enumerate(data_loader): \n",
        "      u_batch    = u_batch.to(device) \n",
        "      batch_size = u_batch.shape[0]\n",
        "      train_batch_size = d.shape[0] # re-define if batch size changes\n",
        "      Phi.train()\n",
        "      optimizer.zero_grad()\n",
        "      u = Phi(d.to(device), max_depth=max_depth, eps=eps) # add snippet for hiding\n",
        "      output = criterion(u, u_batch)\n",
        "      train_loss = output.detach().cpu().numpy()\n",
        "      loss_ave += train_loss * train_batch_size\n",
        "      output.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      tepoch.update(1)\n",
        "      tepoch.set_postfix(train_loss=\"{:5.2e}\".format(train_loss),\n",
        "                            depth=\"{:5.1f}\".format(Phi.depth))\n",
        "    \n",
        "    if epoch%1 == 0:\n",
        "        # compute test image \n",
        "        Phi.eval()\n",
        "        u_test_approx = Phi(data_obs_test[0,:,:,:], max_depth=max_depth, eps=eps)\n",
        "\n",
        "        plt.figure()\n",
        "        plt.subplot(2,2,1)\n",
        "        plt.imshow(u_batch[0,0,:,:].cpu(), vmin=0, vmax=1)\n",
        "        plt.title('u true train')\n",
        "        plt.subplot(2,2,2)\n",
        "        plt.imshow(u[0,0,:,:].detach().cpu(), vmin=0, vmax=1)\n",
        "        plt.title('u approx train')\n",
        "        plt.subplot(2,2,3)\n",
        "        plt.imshow(u_test[0,0,:,:].cpu(), vmin=0, vmax=1)\n",
        "        plt.title('u true test')\n",
        "        plt.subplot(2,2,4)\n",
        "        plt.imshow(u_test_approx[0,0,:,:].detach().cpu(), vmin=0, vmax=1)\n",
        "        plt.title('u approx test')\n",
        "        plt.show() \n",
        "        Phi.train() \n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # Save weights\n",
        "    # ---------------------------------------------------------------------\n",
        "    if loss_ave < best_loss:\n",
        "        best_loss = loss_ave\n",
        "        state = {\n",
        "            'Phi_state_dict': Phi.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'lr_scheduler': lr_scheduler\n",
        "        }\n",
        "        file_name = './drive/MyDrive/FixedPointNetworks/Feasible_FPN_Ellipses_weights.pth'\n",
        "        torch.save(state, file_name)\n",
        "        print('\\nModel weights saved to ' + file_name)        \n",
        "\n",
        "  loss_ave = loss_ave/len(data_loader.dataset)\n",
        "  end_time_epoch = time.time()\n",
        "  time_epoch = end_time_epoch - start_time_epoch\n",
        "  lr_scheduler.step()\n",
        "  print(fmt.format(epoch+1, max_epochs, loss_ave, Phi.depth, \n",
        "                   optimizer.param_groups[0]['lr'],\n",
        "                   time_epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyxCl1Id_Fwb"
      },
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "n_samples = u_test.shape[0]\n",
        "\n",
        "data_test     = TensorDataset(u_test, data_obs_test)\n",
        "test_data_loader     = DataLoader(dataset=data_test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "def compute_avg_SSIM_PSNR(u_true, u_gen, n_mesh, data_range):\n",
        "    # assumes images are size n_samples x n_features**2 and are detached\n",
        "    n_samples = u_true.shape[0]\n",
        "    u_true = u_true.reshape(n_samples, n_mesh, n_mesh).cpu().numpy()\n",
        "    u_gen  = u_gen.reshape(n_samples, n_mesh, n_mesh).cpu().numpy()\n",
        "    ssim_val = 0\n",
        "    psnr_val = 0\n",
        "    for j in range(n_samples):\n",
        "        ssim_val = ssim_val + ssim(u_true[j,:,:], u_gen[j,:,:], data_range=data_range)\n",
        "        psnr_val = psnr_val + psnr(u_true[j,:,:], u_gen[j,:,:], data_range=data_range)\n",
        "    return ssim_val/n_samples, psnr_val/n_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrt0leh7qg59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77f8dc53-14ee-4cb2-883c-054826272e83"
      },
      "source": [
        "test_loss_ave = 0\n",
        "test_PSNR_ave = 0\n",
        "test_SSIM_ave = 0\n",
        "with torch.no_grad():\n",
        "    for idx, (u_batch, d) in enumerate(test_data_loader): \n",
        "\n",
        "        u_batch    = u_batch.to(device) \n",
        "        batch_size = u_batch.shape[0]\n",
        "        temp       = u_batch.view(batch_size, -1)\n",
        "        temp       = temp.permute(1,0)        \n",
        "        test_batch_size = d.shape[0] \n",
        "        Phi.eval()\n",
        "        u = Phi(d, max_depth=max_depth, eps=eps) \n",
        "        output = criterion(u, u_batch)\n",
        "        test_loss = output.detach().cpu().numpy()\n",
        "        test_SSIM, test_PSNR = compute_avg_SSIM_PSNR(u_batch, u, 128, 1)\n",
        "        test_PSNR_ave += test_PSNR * test_batch_size\n",
        "        test_loss_ave += test_loss * test_batch_size\n",
        "        test_SSIM_ave += test_SSIM * test_batch_size\n",
        "\n",
        "        print('test_PSNR = {:7.3e}'.format(test_PSNR))\n",
        "        print('test_SSIM = {:7.3e}'.format(test_SSIM))\n",
        "        print('test_loss = {:7.3e}'.format(test_loss))\n",
        "        if idx%1 == 0:\n",
        "            # compute test image \n",
        "            plt.figure()\n",
        "            plt.subplot(1,2,1)\n",
        "            plt.imshow(u_batch[0,0,:,:].cpu(), vmin=0, vmax=1)\n",
        "            plt.title('u true')\n",
        "            plt.subplot(1,2,2)\n",
        "            plt.imshow(u[0,0,:,:].detach().cpu(), vmin=0, vmax=1)\n",
        "            plt.title('u approx')\n",
        "            plt.show()  \n",
        "\n",
        "print('\\n\\nSUMMARY')\n",
        "print('test_loss_ave =  {:7.3e}'.format(test_loss_ave / 1000))\n",
        "print('test_PSNR_ave =  {:7.3e}'.format(test_PSNR_ave / 1000))\n",
        "print('test_SSIM_ave =  {:7.3e}'.format(test_SSIM_ave / 1000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDWZLuTs_Dpl"
      },
      "source": [
        "ind_val = 0\n",
        "\n",
        "u = Phi(data_obs_test[ind_val,:,:,:]).view(128,128)\n",
        "u_true = u_test[ind_val,0,:,:]\n",
        "def string_ind(index):\n",
        "    if index < 10:\n",
        "        return '000' + str(index)\n",
        "    elif index < 100:\n",
        "        return '00' + str(index)\n",
        "    elif index < 1000:\n",
        "        return '0' + str(index)\n",
        "    else:\n",
        "        return str(index)\n",
        "\n",
        "cmap = 'gray'\n",
        "fig = plt.figure()\n",
        "plt.imshow(np.rot90(u.detach().cpu().numpy()),cmap=cmap, vmin=0, vmax=1)\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "save_loc = './drive/MyDrive/FixedPointNetworks/Learned_Feasibility_Ellipse_FFPN_ind_' + string_ind(ind_val) + '.pdf'\n",
        "plt.savefig(save_loc,bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"SSIM: \", compute_avg_SSIM_PSNR(u_true.view(1,128,128), u.view(1,128,128).detach(), 128, 1))\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# TRUE\n",
        "#------------------------------------------------------------\n",
        "\n",
        "cmap = 'gray'\n",
        "fig = plt.figure()\n",
        "plt.imshow(np.rot90(u_true.detach().cpu().numpy()),cmap=cmap, vmin=0, vmax=1)\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "save_loc = './drive/MyDrive/FixedPointNetworks/Learned_Feasibility_Ellipse_GT_ind_' + string_ind(ind_val) + '.pdf'\n",
        "plt.savefig(save_loc,bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}